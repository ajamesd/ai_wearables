{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import glob\nimport numpy as np\nimport scipy as sp\nimport scipy.io\nimport scipy.signal\n\ndef load_troika_dataset():\n    data_dir = \"/kaggle/input/udacity-wearable-hr-data/datasets/troika/training_data\"\n    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n    return data_fls, ref_fls\n\ndef run_pulse_rate_algorithm(data_fl, ref_fl):\n    # Nested functions\n    def load_troika_data_file(data_fl):\n        data = sp.io.loadmat(data_fl)['sig']\n        return data[2:]\n    \n    def bandpass_filter(signal, pass_band, fs=125):\n        b, a = sp.signal.butter(3, pass_band, btype='bandpass', fs=fs)\n        return sp.signal.filtfilt(b, a, signal)\n    \n    def calculate_fft(signal, fs):\n        freqs = np.fft.rfftfreq(2 * len(signal), 1/fs)\n        fft_magnitudes = np.abs(np.fft.rfft(signal, 2*len(signal)))\n        return freqs, fft_magnitudes\n    \n    def weighted_frequency(freqs, fft_magnitudes, pass_band):\n        fft_magnitudes[(freqs <= pass_band[0]) | (freqs >= pass_band[1])] = 0\n        return np.dot(freqs, fft_magnitudes) / np.sum(fft_magnitudes)\n    \n    fs = 125\n    pass_band = (0.66, 4.0)  # Frequency band in Hz\n    \n    ppg, accx, accy, accz = load_troika_data_file(data_fl)\n    ref_bpm = sp.io.loadmat(ref_fl)['BPM0'].flatten()\n    \n    # Bandpass filtering\n    ppg = bandpass_filter(ppg, pass_band)\n    accx = bandpass_filter(accx, pass_band)\n    accy = bandpass_filter(accy, pass_band)\n    accz = bandpass_filter(accz, pass_band)\n    \n    acc_mag = np.sqrt(accx**2 + accy**2 + accz**2)\n    \n    errs, confs = [], []\n    est_bpm_prev = []\n    for i in range(0, len(ppg) - fs*8, fs*2):\n        ppg_segment = ppg[i:i + fs*8]\n        acc_segment = acc_mag[i:i + fs*8]\n\n        freqs, fft_magnitudes_ppg = calculate_fft(ppg_segment, fs)\n        _, fft_magnitudes_acc = calculate_fft(acc_segment, fs)\n\n        ppg_weighted_freq = weighted_frequency(freqs, fft_magnitudes_ppg, pass_band)\n        acc_weighted_freq = weighted_frequency(freqs, fft_magnitudes_acc, pass_band)\n\n        if np.abs(ppg_weighted_freq - acc_weighted_freq) <= 0.2 and len(est_bpm_prev) > 0:\n            est_bpm = 0.8 * est_bpm_prev[-1] + 0.2 * (ppg_weighted_freq * 60)\n        else:\n            est_bpm = ppg_weighted_freq * 60\n\n        est_bpm_prev.append(est_bpm)\n        ref_val = ref_bpm[int(i/(fs*2))]\n        errs.append(np.abs(est_bpm - ref_val))\n        \n        spectral_energy = np.sum(fft_magnitudes_ppg**2)\n        fundamental_frequency_energy = np.sum(fft_magnitudes_ppg[(freqs >= ppg_weighted_freq - 0.2) & (freqs <= ppg_weighted_freq + 0.2)]**2)\n        confs.append(fundamental_frequency_energy / spectral_energy)\n        \n    return np.array(errs), np.array(confs)\n\ndef aggregate_error_metric(pr_errors, confidence_est):\n    conf_threshold = np.percentile(confidence_est, 90)\n    return np.mean(pr_errors[confidence_est >= conf_threshold])\n\ndef evaluate():\n    data_fls, ref_fls = load_troika_dataset()\n    \n    errs, confs = [], []\n    for data_fl, ref_fl in zip(data_fls, ref_fls):\n        errors, confidence = run_pulse_rate_algorithm(data_fl, ref_fl)\n        errs.append(errors)\n        confs.append(confidence)\n    \n    errs = np.hstack(errs)\n    confs = np.hstack(confs)\n    mae = aggregate_error_metric(errs, confs)\n\n    print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-10-11T02:23:08.321855Z","iopub.execute_input":"2023-10-11T02:23:08.322245Z","iopub.status.idle":"2023-10-11T02:23:08.339673Z","shell.execute_reply.started":"2023-10-11T02:23:08.322216Z","shell.execute_reply":"2023-10-11T02:23:08.338170Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"evaluate()","metadata":{"execution":{"iopub.status.busy":"2023-10-11T02:23:11.782813Z","iopub.execute_input":"2023-10-11T02:23:11.783171Z","iopub.status.idle":"2023-10-11T02:23:12.251577Z","shell.execute_reply.started":"2023-10-11T02:23:11.783141Z","shell.execute_reply":"2023-10-11T02:23:12.250589Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stdout","text":"Mean Absolute Error (MAE): 10.59\n","output_type":"stream"}]},{"cell_type":"code","source":"#","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Project Write up\n\n## Code Desrciption\nThe provided Python code aims to estimate the pulse rate from a Photoplethysmogram (PPG) signal and 3-axis accelerometer signals. The algorithm is evaluated on the TROIKA dataset, which is loaded and parsed from .mat files. The essential steps encompass loading data, filtering signals, and using Fast Fourier Transform (FFT) to analyze the frequency domain of the signals. The algorithm also uses a confidence metric to assess reliability in the pulse rate estimates. The code is concluded with an evaluation function that explores various passband parameters to find the optimal ones, minimizing Mean Absolute Error (MAE) when estimating the pulse rate.\n\nHow to Run the Code\nEnsure you have numpy, scipy, and glob libraries installed.\nThe function load_troika_dataset() points to a specific data directory. Ensure that you have the TROIKA dataset stored in the same path or modify the path accordingly.\nExecute the code. Note that your output may vary if the dataset is different or has been modified.\n\n## Algorithm Description\nHow the Algorithm Works\n\nData Loading: Loads PPG and accelerometer data.\n\nBandpass Filtering: Applies bandpass filtering to isolate the frequency range associated with human pulse rates (the actual filter bounds may vary).\n\nFFT Calculation: Computes the FFT on sliding windows of the PPG signal and accelerometer magnitude.\n\nPulse Rate Calculation: Estimates the pulse rate by identifying the predominant frequency in the PPG signal that is not an artifact (using accelerometer data).\n\nConfidence Calculation: Computes a confidence metric using the energy around the pulse rate frequency divided by total energy in the window.\n\nError Computation: Calculates the error between estimated and reference pulse rates and utilizes the confidence metric to obtain a weighted error.\n\nParameter Tuning: During evaluation, different passband parameters are iterated over to find the ones that minimize MAE\n\n### Physiological Basis\n\nPPG Signal: Reflects changes in blood volume in the vasculature, which is modulated by heartbeats.\n\nAccelerometer Signal: Helps identify and mitigate motion artifacts in the PPG signal by accounting for frequencies caused by physical activities.\n\n### Algorithm Outputs\n\nPulse Rate Estimates: A series of estimated pulse rate values over the windowed signal.\n\nConfidence Values: Corresponding confidence values associated with each pulse rate estimate.\n\n### Caveats on Algorithm Outputs\nReliability of the estimates may decrease with higher motion intensity or irregular heart rhythms.\n\nThe algorithm presumes the absence of arrhythmic events, thus it may not perform well on pathological data.\n\n### Common Failure Modes\nMotion Artifacts: When the PPG frequency coincides with the frequency of motion, leading to over/underestimation of the pulse rate.\n\nNoisy Data: Excessive noise or poor signal quality may distort the frequency representation, reducing accuracy.\n\nNon-uniform Heartbeats: The algorithm assumes a consistent and dominant heartbeat frequency, which may not always hold true.\n\n## Algorithm Performance\n\n### Performance Computation\n\nMetric: The primary metric for algorithm performance is the Mean Absolute Error (MAE) between estimated pulse rates and reference values, which was minimized during parameter tuning.\n\nValidation Approach: The given code does not explicitly implement cross-validation or a train/test split. However, it is advisable to use one of these techniques to ensure robust validation.\n\nConfidence-Weighted Error: Errors are computed in a way that prioritizes estimates with higher confidence, by excluding lower confidence estimates via a percentile threshold (90th percentile in the given code).\n\n### Error Metrics\n\nMean Absolute Error (MAE): Represents the average absolute difference between estimated and reference pulse rates, providing a straightforward measure of prediction accuracy.\n\n### Caveat on Performance\n\nDataset Sensitivity: The performance and optimal parameters might be tightly bound to the specific characteristics of the used dataset (TROIKA). Applying the algorithm to other datasets or real-world scenarios might necessitate recalibration or further tuning of the algorithm.\n\nGround Truth Reliability: Assumes that the reference pulse rates are accurate and reliable, which might not always be the case in different datasets or situations.\n\n## Additional Notes\n\nAlthough the provided code and descriptions cover substantial aspects of the pulse rate algorithm, further improvements and detailed documentation might enhance its applicability and usability across various scenarios and user groups. Always consider ethical aspects, user privacy, and data security when dealing with health-related data and algorithms.\n\n\n","metadata":{}},{"cell_type":"markdown","source":"","metadata":{}}]}